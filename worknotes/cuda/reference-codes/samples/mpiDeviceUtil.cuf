program main

    use mpi
    use cudafor
    use mpiDeviceUtil

    implicit none
    integer, parameter:: n = 1024*1024
    ! mpi
    character(len=100):: hostname
    integer:: procid, numprocs, ierr, namelength
    ! device
    type(cudaDeviceProp):: prop
    integer(int_ptr_kind()):: freeB, totalB, freeA, totalA
    real, device, allocatable:: d(:)
    integer:: deviceID, i, istat

    call MPI_INIT(ierr)
    call MPI_COMM_RANK(MPI_COMM_WORLD, procid, ierr)
    call MPI_COMM_SIZE(MPI_COMM_WORLD, numprocs, ierr)

    ! get and set unique device
    call assignDevice(procid, numprocs, deviceID)

    ! print hostname and device ID for each rank
    call hostnm(hostname)
    do i = 0, numprocs-1
        call MPI_BARRIER(MPI_COMM_WORLD, ierr)
        if (i == procid) write(*,"(' [',i0,'] host: ', a, ',  device: ', i0)") procid, trim(hostname), deviceID
    end do

    ! get memory use before large allocations
    istat = cudaMemGetInfo(freeB, totalB)

    ! allocate memory on each device
    allocate(d(n))

    ! get free memory after allocation
    istat = cudaMemGetInfo(freeA, totalA)

    do i = 0, numprocs-1
        call MPI_BARRIER(MPI_COMM_WORLD, ierr)
        if (i == procid) write(*,"('  [', i0, '] ', 'device arrays allocated: ', i0)") procid, (freeB-freeA)/n/4
    end do

    deallocate(d)

    call MPI_FINALIZE(ierr)

end program main