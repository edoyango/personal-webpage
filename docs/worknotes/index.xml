<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Landing on Ed&#39;s Space - Notes</title>
    <link>/worknotes/</link>
    <description>Recent content in Landing on Ed&#39;s Space - Notes</description>
    <generator>Hugo</generator>
    <language>en</language>
    <atom:link href="/worknotes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A Basic Comparison of C&#43;&#43; vs Fortran</title>
      <link>/worknotes/docs/f-cpp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/f-cpp/</guid>
      <description>&lt;h1 id=&#34;a-basic-comparison-of-c-vs-fortran&#34;&gt;&#xA;  A Basic Comparison of C++ vs Fortran&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#a-basic-comparison-of-c-vs-fortran&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;I&amp;rsquo;m an avid user of Fortran and this is pretty well known in my team. I&amp;rsquo;m not particularly evangalistic about using&#xA;Fortran, but I do feel it has its place in modern programming, despite the fact that it&amp;rsquo;s one of the oldest programming&#xA;languages out there. This has kind of been echoed by other Fortran users. For example, in &#xA;  &lt;a href=&#34;https://arxiv.org/pdf/2301.02432.pdf&#34;&gt;Matsuoka et al. (2023)&lt;/a&gt;,&#xA;They declare that &amp;ldquo;Fortran is dead, long live the DSL!&amp;rdquo; is a HPC myth. They go on to explain that the high performance&#xA;of Fortran is not easily reproduced even in languages like C.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Combining the Orange Pi 5 Pro and YOLOv5 for bird detection</title>
      <link>/worknotes/docs/pi/yolov5-orangepi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/pi/yolov5-orangepi/</guid>
      <description>&lt;h1 id=&#34;combining-the-orange-pi-5-pro-and-yolov5-for-bird-detection&#34;&gt;&#xA;  Combining the Orange Pi 5 Pro and YOLOv5 for bird detection&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#combining-the-orange-pi-5-pro-and-yolov5-for-bird-detection&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;I started this project to record and identify the birds that we saw on our verandah throughout the day, as well as an&#xA;excuse to learn about object detection. I aimed at using YOLO mainly because the &lt;code&gt;ultralytics&lt;/code&gt; package is very easy to&#xA;use and the performance-accuracy tradeoff was good.&lt;/p&gt;&#xA;&lt;p&gt;When I first got started, it was quite easy to play with &lt;code&gt;ultralytics&lt;/code&gt; and its latest iterations of YOLO on my laptop,&#xA;but my main constraint was that I didn&amp;rsquo;t have any machines that were a good (and affordable) candidate to process the&#xA;videos. This was mainly because inference on GPUs was fairly resource intensive and we needed the GPUs for other daily&#xA;resource-intensive use cases like gaming, work, or image/video editing.&lt;/p&gt;</description>
    </item>
    <item>
      <title>CUDA &#43; NVHPC on WSL</title>
      <link>/worknotes/docs/cuda/cuda-wsl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/cuda/cuda-wsl/</guid>
      <description>&lt;h1 id=&#34;installing-cuda--nvhpc-on-wsl&#34;&gt;&#xA;  Installing CUDA + NVHPC on WSL&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#installing-cuda--nvhpc-on-wsl&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This page describes the steps to setup CUDA and NVHPC within the WSL2 container (Windows 10) - avoiding the need for dual-boot or a separate Linux PC. Note that WSL2 must not have been installed when beginning these steps.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Install the latest Windows CUDA graphics driver&lt;/li&gt;&#xA;&lt;li&gt;Install WSL2&#xA;&lt;ul&gt;&#xA;&lt;li&gt;open PowerShell as administrator&lt;/li&gt;&#xA;&lt;li&gt;Make sure to update WSL kernel to latest version wsl &amp;ndash;update&#xA;&lt;ul&gt;&#xA;&lt;li&gt;if accidentally rolled back, follow the instructions here&lt;/li&gt;&#xA;&lt;li&gt;then wsl &amp;ndash;update again&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;check which Linux flavours are available with wsl &amp;ndash;list &amp;ndash;online&lt;/li&gt;&#xA;&lt;li&gt;install the desired flavour by wsl &amp;ndash;install -d &lt;flavour name&gt;&lt;/li&gt;&#xA;&lt;li&gt;start WSL with wsl, or opening the WSL application from the Windows search bar&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;sudo apt update &amp;amp;&amp;amp; sudo apt upgrade -y&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Close and restart WSL&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;sudo apt update &amp;amp;&amp;amp; sudo apt upgrade -y &amp;amp;&amp;amp; sudo apt autoremove -y&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Install CUDA for WSL&#xA;&lt;ul&gt;&#xA;&lt;li&gt;check which CUDA version is compatible with the desired version NVHPC kit here&lt;/li&gt;&#xA;&lt;li&gt;select the correct CUDA version here&lt;/li&gt;&#xA;&lt;li&gt;Select the right setup: Linux -&amp;gt; x86_64 -&amp;gt; WSL-Ubuntu -&amp;gt; 2.0 -&amp;gt; dev (local)&lt;/li&gt;&#xA;&lt;li&gt;before beginning install, delete old GPG key sudo apt-key del 7fa2af80&lt;/li&gt;&#xA;&lt;li&gt;Perform the install with code below:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://developer.download.nvidia.com/compute/cuda/11.7.1/local_installers/cuda-repo-wsl-ubuntu-11-7-local_11.7.1-1_amd64.deb&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo dpkg -i cuda-repo-wsl-ubuntu-11-7-local_11.7.1-1_amd64.deb&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo cp /var/cuda-repo-wsl-ubuntu-11-7-local/cuda-*-keyring.gpg /usr/share/keyrings/&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get update&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get -y install cuda&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;7&#34;&gt;&#xA;&lt;li&gt;Install NVHPC&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Download the desired NVHPC kit&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;tar xzvf nvhpc*.tar.gz&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;sudo nvhpc*/install&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;uninstalling-nvhpc-and-cuda&#34;&gt;&#xA;  Uninstalling NVHPC and CUDA&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#uninstalling-nvhpc-and-cuda&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo rm /opt/nvidia/hpc_sdk&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get purge -y cuda &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo apt-get autoremove -y&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo rm /usr/share/keyrings/cuda-*-keyring.gpg&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo dpdkg -P cuda-repo-wsl-ubuntu-*-*-local_*amd64.deb&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can then perform the installation steps again for the desired NVHPC-CUDA combination&lt;/p&gt;</description>
    </item>
    <item>
      <title>Direct pair search</title>
      <link>/worknotes/docs/useful/fixed-cutoff-direct-pair-search/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/useful/fixed-cutoff-direct-pair-search/</guid>
      <description>&lt;h1 id=&#34;point-pairs-search-with-fixed-cutoff-distance-direct&#34;&gt;&#xA;  Point-pairs search with fixed cutoff distance (direct)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#point-pairs-search-with-fixed-cutoff-distance-direct&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;description&#34;&gt;&#xA;  Description&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#description&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;I work with point pair searches through particle-based simulations (mostly SPH and DEM). The algorithm here is the most basic way to perform a pair search. It is O(N2) time, so is not useful for any practical applications.&lt;/p&gt;&#xA;&lt;p&gt;I use it frequently to server as a reference when investigating other ways to search for pairs. It&amp;rsquo;s simple to code, so is harder to introduce conceptual and coding errors.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fixed-Radius Neighbour Search Using Thrust</title>
      <link>/worknotes/docs/cuda/frn-thrust/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/cuda/frn-thrust/</guid>
      <description>&lt;h1 id=&#34;fixed-radius-neighbour-search-using-thrust&#34;&gt;&#xA;  Fixed-Radius Neighbour Search Using Thrust&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#fixed-radius-neighbour-search-using-thrust&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This page describes how one might implement the pair-finding algorithm described by &#xA;  &lt;a href=&#34;https://developer.download.nvidia.com/assets/cuda/files/particles.pdf&#34;&gt;Simon Green (2010)&lt;/a&gt;.&#xA;Many implementations of Simon&amp;rsquo;s work exists, such as the &#xA;  &lt;a href=&#34;https://github.com/lxxue/FRNN&#34;&gt;FRNN Python package&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-thrust&#34;&gt;&#xA;  Why Thrust?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#why-thrust&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;I would argue that there is a fairly strong incentive to make GPU-accelerated codes portable across different&#xA;hardware platforms. At the time of writing, NVIDIA GPUs are becoming more challenging to get a hold of, and are&#xA;more expensive relative to their competition (i.e., AMD and Intel GPUs). Consequently, it is becoming harder to justify&#xA;writing code exclusively using the CUDA ecosystem.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Motivation</title>
      <link>/worknotes/docs/manual-vectorization/motivation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/manual-vectorization/motivation/</guid>
      <description>&lt;p&gt;SPH is a continuum particle method that is often used for simulations. Typically, the most time consuming part of codes&#xA;that aim to perform SPH simulations, is finding the pairs of SPH particles that are within a fixed-cutoff of each other&#xA;(the pair-search step from herein), and calculating the contribution to particles&amp;rsquo; motion, due to its corresponding&#xA;pair (the force calculation sweep step from herein). These steps can be combined together when organising the code,&#xA;but it&amp;rsquo;s useful to seperate them when needing to re-use the pair list.&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenFOAM cavity case to CFDEM</title>
      <link>/worknotes/docs/cfdem/cavitycfdem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/cfdem/cavitycfdem/</guid>
      <description>&lt;h1 id=&#34;converting-the-openfoam-cavity-example-for-cfdem&#34;&gt;&#xA;  Converting the OpenFOAM cavity example for CFDEM&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#converting-the-openfoam-cavity-example-for-cfdem&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;The cavity case is a good one to start with as it forms the beginning of the&#xA;&#xA;  &lt;a href=&#34;https://www.openfoam.com/documentation/tutorial-guide&#34;&gt;official OpenFOAM tutorials&lt;/a&gt;.&#xA;These steps assume we&amp;rsquo;re using the PUBLIC version of CFDEM which couples&#xA;LIGGGHTS-PUBLIC 3.8.0 and OpenFOAM-5.x. It also assumes that your environment&#xA;variables have already been setup as per the&#xA;&#xA;  &lt;a href=&#34;https://www.cfdem.com/media/CFDEM/docu/CFDEMcoupling_Manual.html#installation&#34;&gt;CFDEM insallation instructions&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;getting-the-case-files&#34;&gt;&#xA;  Getting the case files&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#getting-the-case-files&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;The lid-driven cavity flow example case comes with the OpenFOAM source code. If&#xA;you don&amp;rsquo;t have it already from install OpenFOAM, get it by:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reducing Jetson Nano OS for Server</title>
      <link>/worknotes/docs/pi/trim-jetsonnano/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/pi/trim-jetsonnano/</guid>
      <description>&lt;h1 id=&#34;reducing-jetson-nano-os-for-server&#34;&gt;&#xA;  Reducing Jetson Nano OS for Server&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#reducing-jetson-nano-os-for-server&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;The Nvidia Jetson Nano is a Single Board Computer (SBC) with a scaled-down Nvidia GPU (Tegra X1). I have the 2GB version, the smallest available. The OS that Nvidia forces you to use comes with a full-blown desktop environment, which chews through the 2GB of RAM pretty easily - not leaving as much room as I&amp;rsquo;d like for other things.&lt;/p&gt;&#xA;&lt;p&gt;Consequently, this page is to document the steps to trim down the OS to save disk space and RAM - adding to steps documented elsewhere.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Setting Up Public Webserver on Raspberry Pi</title>
      <link>/worknotes/docs/pi/webserver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/pi/webserver/</guid>
      <description>&lt;h1 id=&#34;setting-up-public-webserver-on-raspberry-pi&#34;&gt;&#xA;  Setting Up Public Webserver on Raspberry Pi&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#setting-up-public-webserver-on-raspberry-pi&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;The instructions here assumes you&amp;rsquo;re using Raspberry Pi Lite as the OS on the Raspberry Pi. Other OS&amp;rsquo; are largely similar though. The main difference will be the packages and package managers, and the firewall tool.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Setup the pi to host the server&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Flash disk with raspberry pi lite. Insert disk into pi and power them on.&lt;/li&gt;&#xA;&lt;li&gt;(follow the instructions &#xA;  &lt;a href=&#34;https://linuxhint.com/install_apache_web_server_ubuntu/&#34;&gt;here&lt;/a&gt; up to step 4)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Setup router to forward http/https/ssh requests to the Raspberry Pi&lt;/p&gt;</description>
    </item>
    <item>
      <title>Setting Up Raspberry Pi Slurm Cluster</title>
      <link>/worknotes/docs/pi/slurm-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/pi/slurm-cluster/</guid>
      <description>&lt;h1 id=&#34;setting-up-raspberry-pi-slurm-cluster&#34;&gt;&#xA;  Setting Up Raspberry Pi Slurm Cluster&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#setting-up-raspberry-pi-slurm-cluster&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Flash disk(s) with raspberry pi lite. Insert disk(s) into pi(s) and power them on.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Run &lt;code&gt;sudo raspi-config&lt;/code&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;update raspi-config&lt;/li&gt;&#xA;&lt;li&gt;change hostname&lt;/li&gt;&#xA;&lt;li&gt;setup ssh&lt;/li&gt;&#xA;&lt;li&gt;change password for pi user&lt;/li&gt;&#xA;&lt;li&gt;set wlan locale&lt;/li&gt;&#xA;&lt;li&gt;set timezone&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;setup login-less ssh between nodes.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;create key on one of the nodes&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;  sudo ssh-keygen # save it somewhere central like in /etc/ssh&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;configure ssh to use the newly created key by editing &lt;code&gt;/etc/ssh/ssh_config&lt;/code&gt; and adding&lt;/p&gt;</description>
    </item>
    <item>
      <title>Snappy Hex Mesh Basics</title>
      <link>/worknotes/docs/cfdem/snappyhexmesh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/cfdem/snappyhexmesh/</guid>
      <description>&lt;h1 id=&#34;snappy-hex-mesh-basics&#34;&gt;&#xA;  Snappy Hex Mesh Basics&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#snappy-hex-mesh-basics&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This is a summary of meshing in OpenFOAM using the &lt;code&gt;snappyHexMesh&lt;/code&gt; tool. I&amp;rsquo;m writing this in detail because I couldn&amp;rsquo;t find any comprehensive tutorial that is beginner friendly. The ones I could find were like as if they were picking up from where someone else left off. Consequently, this tool is a beginner guide and aims only to recommend easy-to-pickup tools, rather than the most fully featured tools. This only covers absolute basics and creating simple geometries. It only covers &lt;code&gt;snappyhexMesh&lt;/code&gt; tool as &#xA;  &lt;a href=&#34;https://www.openfoam.com/documentation/user-guide/4-mesh-generation-and-conversion/4.4-mesh-generation-with-the-snappyhexmesh-utility&#34;&gt;the user guide for the basic tool &lt;code&gt;blockMesh&lt;/code&gt;&lt;/a&gt; is pretty ok.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cell list pair search</title>
      <link>/worknotes/docs/useful/fixed-cutoff-cell-lists-pair-search/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/useful/fixed-cutoff-cell-lists-pair-search/</guid>
      <description>&lt;h1 id=&#34;point-pairs-search-with-fixed-cutoff-distance-using-cell-lists&#34;&gt;&#xA;  Point-pairs search with fixed cutoff distance (using cell-lists)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#point-pairs-search-with-fixed-cutoff-distance-using-cell-lists&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;description&#34;&gt;&#xA;  Description&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#description&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;This is an improvement to the &#xA;  &lt;a href=&#34;/worknotes/docs/useful/fixed-cutoff-direct-pair-search/&#34;&gt;direct search&lt;/a&gt; algorithm for searching for pairs of points within a cutoff distance. It uses a grid of cells whose side-length is equal to the specified cutoff distance.&lt;/p&gt;&#xA;&lt;p&gt;This is beneficial to performance since for any given point, all its neighbours are guaranteed to be within its own cell, or in adjacent cells. This means that instead of performing a comparison with all other points, comparisons only need to be made to points in the same or adjacent cells.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Coarray Fortran Things</title>
      <link>/worknotes/docs/caf/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/caf/</guid>
      <description>&lt;h1 id=&#34;coarray-fortran-things&#34;&gt;&#xA;  Coarray Fortran Things&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#coarray-fortran-things&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;ignoring the basics. Best tutorial to start with is &#xA;  &lt;a href=&#34;https://github.com/tkoenig1/coarray-tutorial/blob/main/tutorial.md&#34;&gt;this one&lt;/a&gt;. Basic, but couldn&amp;rsquo;t find very beginner friendly ones.&lt;/p&gt;&#xA;&lt;h2 id=&#34;install&#34;&gt;&#xA;  Install&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#install&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;  &lt;a href=&#34;http://www.opencoarrays.org/&#34;&gt;OpenCoarrays&lt;/a&gt; is a library usable with gfortran and uses MPI 1-sided comms as the to perform the communications. install via linuxbrew or spack.&lt;/p&gt;&#xA;&lt;p&gt;Intel compilers don&amp;rsquo;t rely on external libraries and should be ready to use coarrays with intel-MPI. It only requires compilation with &lt;code&gt;-coarray&lt;/code&gt; option.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Speeding Up LIGGGHTS with Intel Compilers and Compiler Options</title>
      <link>/worknotes/docs/cfdem/liggghts-intel-comp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/cfdem/liggghts-intel-comp/</guid>
      <description>&lt;h1 id=&#34;speeding-up-liggghts-with-intel-compilers-and-compiler-options&#34;&gt;&#xA;  Speeding Up LIGGGHTS with Intel Compilers and Compiler Options&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#speeding-up-liggghts-with-intel-compilers-and-compiler-options&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This page looks at using basic optimization options and &#xA;  &lt;a href=&#34;https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html#gs.ndxx16&#34;&gt;Intel OneAPI Compilers&lt;/a&gt; (for x86 CPU architectures) to reduce the run-time of LIGGGHTS.&lt;/p&gt;&#xA;&lt;p&gt;The page will first show the difference in performance of the Intel compilers compared to the GNU compilers and also looks at different compiler options. After hopefully convincing you of why you should use the intel compilers, the page then goes on to explain how to build LIGGGHTS with the Intel compilers.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vectorizing Array Addition</title>
      <link>/worknotes/docs/manual-vectorization/addition/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/manual-vectorization/addition/</guid>
      <description>&lt;h1 id=&#34;vectorizing-array-addition&#34;&gt;&#xA;  Vectorizing Array Addition&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#vectorizing-array-addition&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;A common place to start, is to manually vectorize the addition of two arrays, and storing the result in a third array&#xA;(from herein, ABC addition):&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;abc_base_sgl&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;nelem&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;nelem&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;++&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;c&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;];&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the benchmarking code, the arrays are created with &lt;code&gt;new&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;doing-the-vectorization&#34;&gt;&#xA;  Doing the Vectorization&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#doing-the-vectorization&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;vectorizing-the-abc-function-with-128-bit-vectors-sse-instructions&#34;&gt;&#xA;  Vectorizing the ABC function with 128-bit vectors (SSE instructions)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#vectorizing-the-abc-function-with-128-bit-vectors-sse-instructions&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;This function, manually vectorized, looks like:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;// 128bit width (SSE)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;abc_128_sgl&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;nelem&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;c&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;nelem&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;4&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;__m128&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;v1&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;_mm_loadu_ps&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]);&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;__m128&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;v2&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;_mm_loadu_ps&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]);&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;__m128&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;res&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;_mm_add_ps&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;v1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;v2&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;);&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;_mm_storeu_ps&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;c&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;res&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;);&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that this requires &lt;code&gt;#include &amp;lt;immintrin.h&amp;gt;&lt;/code&gt; to make use of the types and functions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cell list pair search - reducing search space</title>
      <link>/worknotes/docs/useful/fixed-cutoff-cell-lists-pair-searchhalf-search/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/useful/fixed-cutoff-cell-lists-pair-searchhalf-search/</guid>
      <description>&lt;h1 id=&#34;cell-lists-point-pairs-search-with-fixed-cutoff---reducing-search-space&#34;&gt;&#xA;  Cell-lists point-pairs search with fixed cutoff - reducing search space&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#cell-lists-point-pairs-search-with-fixed-cutoff---reducing-search-space&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;description&#34;&gt;&#xA;  Description&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#description&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;  &lt;a href=&#34;/worknotes/docs/useful/fixed-cutoff-cell-lists-pair-search/&#34;&gt;The naive cell-list pair search&lt;/a&gt;, is a good&#xA;start. But a drawback of that implementation is that it searches through &lt;em&gt;all&lt;/em&gt; adjacent cells, and uses an &lt;code&gt;if&lt;/code&gt;&#xA;statement to avoid duplicate checks. However, looping over all adjacent cells still takes time, and the &lt;code&gt;if&lt;/code&gt;&#xA;statement can be expensive by introducing branching.&lt;/p&gt;&#xA;&lt;p&gt;However, to eliminate duplicate checks, we only need to compare particles in the current cell with particles&#xA;in half of the adjacent cells. For instance, if you&amp;rsquo;ve checked particle A in one cell against particle B in a&#xA;neighboring cell, you don&amp;rsquo;t need to check B against A again when you move to that neighboring cell. Hence, you&#xA;can omit some cells from the search for each particle to avoid this redundancy. See below sketches that&#xA;illustrate how coverage is not reduced with this strategy.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vector Sum Reduction</title>
      <link>/worknotes/docs/manual-vectorization/sumreduce/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/manual-vectorization/sumreduce/</guid>
      <description>&lt;h1 id=&#34;vector-sum-reduction&#34;&gt;&#xA;  Vector Sum Reduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#vector-sum-reduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;We now we can add two SIMD vectors together element-by-element. However, I&amp;rsquo;m sure you can imagine scenarios where you&#xA;might want to add all the elements in a vector together i.e., a sum-reduction. This page will explain how to do this&#xA;with 128-bit and 256-bit vectors the approach is different for each vector width. I would show how to do this with&#xA;512-bit vectors, but I don&amp;rsquo;t have a CPU with AVX512 instructions handy.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Faster Vector Sum Reduction</title>
      <link>/worknotes/docs/manual-vectorization/faster-sumreduce/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/manual-vectorization/faster-sumreduce/</guid>
      <description>&lt;h1 id=&#34;faster-vector-sum-reduce&#34;&gt;&#xA;  Faster Vector Sum Reduce&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#faster-vector-sum-reduce&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;In &#xA;  &lt;a href=&#34;/worknotes/docs/manual-vectorization/sumreduce/&#34;&gt;my page introducing vectorized reductions&lt;/a&gt;, I show how to use horizontal adds (&lt;code&gt;hadd&lt;/code&gt;) functions to&#xA;perform the reduction. However, this &#xA;  &lt;a href=&#34;https://stackoverflow.com/questions/6996764/fastest-way-to-do-horizontal-sse-vector-sum-or-other-reduction/35270026&#34;&gt;doesn&amp;rsquo;t produce optimal assembly&lt;/a&gt;, so isn&amp;rsquo;t the fastest way to do things.&lt;/p&gt;&#xA;&lt;p&gt;This page will demonstrate a faster version to do each of the examples shown previously.&lt;/p&gt;&#xA;&lt;h2 id=&#34;single-precision-sse-instructions&#34;&gt;&#xA;  Single precision, SSE instructions&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#single-precision-sse-instructions&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;This section will show a faster sum-reduce example which makes use of 128-bit single precision vectors and SSE&#xA;instructions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>grid dimension hashing</title>
      <link>/worknotes/docs/useful/grid-rows-spatial-hashing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/useful/grid-rows-spatial-hashing/</guid>
      <description>&lt;h1 id=&#34;hashing-grid-cell-indices-based-on-grid-dimensions&#34;&gt;&#xA;  Hashing grid cell indices based on grid dimensions&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#hashing-grid-cell-indices-based-on-grid-dimensions&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;description&#34;&gt;&#xA;  Description&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#description&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;This strategy is based on &#xA;  &lt;a href=&#34;https://developer.download.nvidia.com/assets/cuda/files/particles.pdf&#34;&gt;this NVIDIA article&lt;/a&gt;.&#xA;The idea being that instead of storing indices of particles in a grid data structure, you can convert these 3-valued&#xA;indices to single hashes. These hashes can then be used to sort the particle data so that the particle data is ordered&#xA;based on their grid cell hash index. This is beneficial for GPUs, which is why it&amp;rsquo;s mentioned in the above article, but&#xA;is also useful for CPUs as it iterating over the particle pairs more cache-friendly.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vectorizing A Simple Pair Sweep</title>
      <link>/worknotes/docs/manual-vectorization/sweep/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/manual-vectorization/sweep/</guid>
      <description>&lt;h1 id=&#34;vectorizing-a-simple-pair-sweep&#34;&gt;&#xA;  Vectorizing A Simple Pair Sweep&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#vectorizing-a-simple-pair-sweep&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;One way to perform the force calculation sweep in SPH, is to use a double loop like:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;nelem&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;++&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;j&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;j&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;nelem&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;++&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;j&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;// compare particle i and j&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;// calculate forces&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This is generally not a preferred way to do the force calculations, as the number of operations in this algorithm scales&#xA;with the square of the number of particles. But it&amp;rsquo;s useful for playing around with manual vectorization.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vectorizing Cell-based Pair Search</title>
      <link>/worknotes/docs/manual-vectorization/cll-avx512/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/manual-vectorization/cll-avx512/</guid>
      <description>&lt;h1 id=&#34;vectorizing-cell-based-pair-search&#34;&gt;&#xA;  Vectorizing Cell-based Pair Search&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#vectorizing-cell-based-pair-search&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;To calculate the acceleration of SPH particles, one must first find the pairs. In the case where incompressible or&#xA;weakly-compressible assumptions are used, and where particles&amp;rsquo; kernel radius is fixed, &#xA;  &lt;a href=&#34;https://en.wikipedia.org/wiki/Cell_lists&#34;&gt;the cell-linked list&lt;/a&gt;&#xA;strategy is often employed. The basis of the algorithm is that described on one of &#xA;  &lt;a href=&#34;/worknotes/docs/useful/grid-rows-spatial-hashing/&#34;&gt;my other pages&lt;/a&gt;&#xA;written in Fortran. Below is the C++ version of the main sweep code.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;npairs&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;hashi&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;gridhash&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;];&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;hashi&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;gridhash&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nelem&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;];&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;++&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;hashi&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ii&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;starts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;hashi&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;];&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ii&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;starts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;hashi&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;];&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;++&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ii&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;jj&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ii&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;jj&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;starts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;hashi&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;];&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;++&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;jj&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;sph&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;dr&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ii&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;jj&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ii&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;jj&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dy&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]);&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;pair_i&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ii&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;pair_j&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;jj&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;kh&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;hashbotleft&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;hashi&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ngridy&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;jj&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;starts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;hashbotleft&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;];&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;jj&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;starts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;hashbotleft&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;];&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;++&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;jj&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;sph&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;dr&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ii&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;jj&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ii&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;jj&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dy&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]);&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;pair_i&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ii&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;pair_j&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;jj&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;niac&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;kh&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Some distinctions between this code and the Fortran code is that the positions are seperated into two &lt;code&gt;std::vector&lt;/code&gt;, and&#xA;distance vectors and magnitudes are stored in &lt;code&gt;std::vectors&lt;/code&gt;, as opposed to being discarded immediately (the calculation&#xA;is performed in &lt;code&gt;sph::dr&lt;/code&gt; function). This is useful because these values can be reused lated to calculate kernel values,&#xA;gradients, and particles&amp;rsquo; acceleration.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cell lists pair search without &#34;if&#34;</title>
      <link>/worknotes/docs/useful/fixed-cutoff-pair-search-noifs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/useful/fixed-cutoff-pair-search-noifs/</guid>
      <description>&lt;h1 id=&#34;cell-lists-pair-search-without-if&#34;&gt;&#xA;  Cell lists pair search without &lt;code&gt;if&lt;/code&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#cell-lists-pair-search-without-if&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;description&#34;&gt;&#xA;  Description&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#description&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;So far, the speedup demonstrated from the &#xA;  &lt;a href=&#34;/worknotes/docs/useful/grid-rows-spatial-hashing/&#34;&gt;fixed-cutoff cell-lists pair search algorithm&lt;/a&gt;&#xA;is pretty great. One last change we can make to improve things, is to remove any &lt;code&gt;if&lt;/code&gt; statements when searching adjacent&#xA;cells. &lt;code&gt;if&lt;/code&gt;&amp;rsquo;s are undesirable because they introduce &#xA;  &lt;a href=&#34;https://en.wikipedia.org/wiki/Branch_%28computer_science%29&#34;&gt;branching&lt;/a&gt;&#xA;and harms performance. I&amp;rsquo;ve found that it can be beneficial to remove &lt;code&gt;if&lt;/code&gt; statements, even if it means a bit more&#xA;computation/assignments are performed.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Z-curve hashing</title>
      <link>/worknotes/docs/useful/z-curve-spatial-hashing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/useful/z-curve-spatial-hashing/</guid>
      <description>&lt;h1 id=&#34;hashing-grid-cell-indices-based-on-z-order-curve&#34;&gt;&#xA;  Hashing grid cell indices based on Z-order curve&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#hashing-grid-cell-indices-based-on-z-order-curve&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;description&#34;&gt;&#xA;  Description&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#description&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;code-fortran&#34;&gt;&#xA;  Code (Fortran)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#code-fortran&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fortran&#34; data-lang=&#34;fortran&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;Coming&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;soon&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;...&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title></title>
      <link>/worknotes/docs/cuda/hidden/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/worknotes/docs/cuda/hidden/</guid>
      <description>&lt;h1 id=&#34;this-page-is-hidden-in-menu&#34;&gt;&#xA;  This page is hidden in menu&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#this-page-is-hidden-in-menu&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h1 id=&#34;quondam-non-pater-est-dignior-ille-eurotas&#34;&gt;&#xA;  Quondam non pater est dignior ille Eurotas&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#quondam-non-pater-est-dignior-ille-eurotas&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;latent-te-facies&#34;&gt;&#xA;  Latent te facies&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#latent-te-facies&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Lorem markdownum arma ignoscas vocavit quoque ille texit mandata mentis ultimus,&#xA;frementes, qui in vel. Hippotades Peleus &#xA;  &lt;a href=&#34;http://gratia.net/tot-qua.php&#34;&gt;pennas&#xA;conscia&lt;/a&gt; cuiquam Caeneus quas.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Pater demittere evincitque reddunt&lt;/li&gt;&#xA;&lt;li&gt;Maxime adhuc pressit huc Danaas quid freta&lt;/li&gt;&#xA;&lt;li&gt;Soror ego&lt;/li&gt;&#xA;&lt;li&gt;Luctus linguam saxa ultroque prior Tatiumque inquit&lt;/li&gt;&#xA;&lt;li&gt;Saepe liquitur subita superata dederat Anius sudor&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;cum-honorum-latona&#34;&gt;&#xA;  Cum honorum Latona&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#cum-honorum-latona&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;O fallor &#xA;  &lt;a href=&#34;http://www.spectataharundine.org/aquas-relinquit.html&#34;&gt;in sustinui&#xA;iussorum&lt;/a&gt; equidem.&#xA;Nymphae operi oris alii fronde parens dumque, in auro ait mox ingenti proxima&#xA;iamdudum maius?&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
